{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../input/train.csv\", names=['Store','Dept','Date','weeklySales','isHoliday'],sep=',', header=0)\n",
    "features = pd.read_csv(\"../input/features.csv\",sep=',', header=0,\n",
    "                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n",
    "                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\n",
    "stores = pd.read_csv(\"../input/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\n",
    "dataset = dataset.merge(stores, how='left').merge(features, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(dataset, column):\n",
    "    plt.figure()\n",
    "    plt.scatter(dataset[column] , dataset['weeklySales'])\n",
    "    plt.ylabel('weeklySales')\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(dataset, 'Fuel_Price')\n",
    "scatter(dataset, 'Size')\n",
    "scatter(dataset, 'CPI')\n",
    "scatter(dataset, 'Type')\n",
    "scatter(dataset, 'isHoliday')\n",
    "scatter(dataset, 'Unemployment')\n",
    "scatter(dataset, 'Temperature')\n",
    "scatter(dataset, 'Store')\n",
    "scatter(dataset, 'Dept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 14))\n",
    "corr = dataset.corr()\n",
    "c = plt.pcolor(corr)\n",
    "plt.yticks(np.arange(0.5, len(corr.index), 1), corr.index)\n",
    "plt.xticks(np.arange(0.5, len(corr.columns), 1), corr.columns)\n",
    "fig.colorbar(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in dataset.groupby([\"Store\", \"Dept\"]):\n",
    "    plt.title(name)\n",
    "    plt.scatter(range(len(group)), group[\"weeklySales\"])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=[\"Type\"])\n",
    "dataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\n",
    "dataset['Month'] = pd.to_datetime(dataset['Date']).dt.month\n",
    "dataset = dataset.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    knn = KNeighborsRegressor(n_neighbors=10)\n",
    "    return knn\n",
    "\n",
    "def extraTreesRegressor():\n",
    "    clf = ExtraTreesRegressor(n_estimators=100,max_features='auto', verbose=1, n_jobs=1)\n",
    "    return clf\n",
    "\n",
    "def randomForestRegressor():\n",
    "    clf = RandomForestRegressor(n_estimators=100,max_features='log2', verbose=1)\n",
    "    return clf\n",
    "\n",
    "def svm():\n",
    "    clf = SVR(kernel='rbf', gamma='auto')\n",
    "    return clf\n",
    "\n",
    "def nn():\n",
    "    clf = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', verbose=3)\n",
    "    return clf\n",
    "\n",
    "def predict_(m, test_x):\n",
    "    return pd.Series(m.predict(test_x))\n",
    "\n",
    "def model_():\n",
    "#     return knn()\n",
    "    return extraTreesRegressor()\n",
    "#     return svm()\n",
    "#     return nn()\n",
    "#     return randomForestRegressor()    \n",
    "\n",
    "def train_(train_x, train_y):\n",
    "    m = model_()\n",
    "    m.fit(train_x, train_y)\n",
    "    return m\n",
    "\n",
    "def train_and_predict(train_x, train_y, test_x):\n",
    "    m = train_(train_x, train_y)\n",
    "    return predict_(m, test_x), m\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "splited = []\n",
    "# dataset2 = dataset.copy()\n",
    "for name, group in dataset.groupby([\"Store\", \"Dept\"]):\n",
    "    group = group.reset_index(drop=True)\n",
    "    trains_x = []\n",
    "    trains_y = []\n",
    "    tests_x = []\n",
    "    tests_y = []\n",
    "    if group.shape[0] <= 5:\n",
    "        f = np.array(range(5))\n",
    "        np.random.shuffle(f)\n",
    "        group['fold'] = f[:group.shape[0]]\n",
    "        continue\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(group):\n",
    "        group.loc[test_index, 'fold'] = fold\n",
    "        fold += 1\n",
    "    splited.append(group)\n",
    "\n",
    "splited = pd.concat(splited).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "error_cv = 0\n",
    "best_error = np.iinfo(np.int32).max\n",
    "for fold in range(5):\n",
    "    dataset_train = splited.loc[splited['fold'] != fold]\n",
    "    dataset_test = splited.loc[splited['fold'] == fold]\n",
    "    train_y = dataset_train['weeklySales']\n",
    "    train_x = dataset_train.drop(columns=['weeklySales', 'fold'])\n",
    "    test_y = dataset_test['weeklySales']\n",
    "    test_x = dataset_test.drop(columns=['weeklySales', 'fold'])\n",
    "    print(dataset_train.shape, dataset_test.shape)\n",
    "    predicted, model = train_and_predict(train_x, train_y, test_x)\n",
    "    weights = test_x['isHoliday'].replace(True, 5).replace(False, 1)\n",
    "    error = calculate_error(test_y, predicted, weights)\n",
    "    error_cv += error\n",
    "    print(fold, error)\n",
    "    if error < best_error:\n",
    "        print('Find best model')\n",
    "        best_error = error\n",
    "        best_model = model\n",
    "error_cv /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
