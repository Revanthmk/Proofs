{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "data_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "train = data_raw.copy(deep=True)\n",
    "data_all = [train, data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_all:\n",
    "    dataset.drop(['Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace=True)\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n",
    "    for c in set(dataset['Pclass']):\n",
    "        for s in set(dataset['Sex']):\n",
    "            age_median = dataset[(dataset['Pclass'] == c) & (dataset['Sex'] == s)]['Age'].median()\n",
    "            dataset.loc[(dataset['Age'].isnull()) & (dataset['Pclass'] == c) & (dataset['Sex'] == s), 'Age'] = age_median\n",
    "train.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "# Create\n",
    "def get_titles(series):\n",
    "    return series.str.extract(' ([a-zA-Z]+)\\.', expand=False)\n",
    "\n",
    "for dataset in data_all:\n",
    "    dataset['FamilySize'] = dataset['Parch'] + dataset['SibSp'] + 1\n",
    "    dataset['IsAlone'] = (dataset['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    dataset['Title'] = get_titles(dataset['Name'])\n",
    "    title_counts = dataset['Title'].value_counts()\n",
    "    dataset['Title'] = dataset['Title'].map(lambda t: t if title_counts[t] >= 10 else 'Rare')\n",
    "    dataset.drop('Name', axis=1, inplace=True)\n",
    "    \n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'], 5)\n",
    "\n",
    "# Convert\n",
    "categorical_cols = ['Sex', 'Embarked', 'Title', 'AgeBin', 'FareBin']\n",
    "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone']\n",
    "\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "for dataset in data_all:\n",
    "    for col in categorical_cols:\n",
    "        dataset[col + '_Code'] = le.fit_transform(dataset[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    sns.heatmap(df.corr(), cmap=colormap, annot=True)\n",
    "    plt.title('Pearson Correlation of Features', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(axis=0, subset=['Survived'])\n",
    "targ_col = 'Survived'\n",
    "# print('int & float cols:', train.columns[(train.dtypes == int) | (train.dtypes == float)].values)\n",
    "\n",
    "feature_cols = ['Pclass', 'FamilySize', 'IsAlone', 'Sex_Code', 'Embarked_Code',\n",
    "        'Title_Code', 'AgeBin_Code', 'FareBin_Code']\n",
    "# print('chosen cols:', feature_cols)\n",
    "# train[feature_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(**{'n_jobs': -1, 'n_neighbors': 7}),\n",
    "    SVC(**{'C': 0.390625, 'kernel': 'poly', 'probability': True, 'random_state': 0}),\n",
    "    LinearSVC(**{'C': 25.0, 'dual': False, 'loss': 'squared_hinge', 'max_iter': 25000, 'penalty': 'l1', 'random_state': 0}),\n",
    "    DecisionTreeClassifier(**{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 8, 'random_state': 0}),\n",
    "    RandomForestClassifier(**{'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 8, 'n_estimators': 300, 'n_jobs': -1, 'random_state': 0}),\n",
    "    AdaBoostClassifier(**{'algorithm': 'SAMME', 'learning_rate': 0.3, 'n_estimators': 300, 'random_state': 0}),jobs': -1, 'random_state': 0}),\n",
    "    RidgeClassifier(**{'alpha': 0.5, 'normalize': True, 'random_state': 0}),\n",
    "    GaussianProcessClassifier(**{'max_iter_predict': 10, 'n_jobs': -1, 'random_state': 0}),\n",
    "    XGBClassifier(**{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 10, 'n_jobs': -1, 'random_state': 0, 'reg_alpha': 0.16, 'reg_lambda': 2.56}),\n",
    "    LGBMClassifier(**{'boosting_type': 'goss', 'learning_rate': 0.1, 'n_estimators': 1000, 'n_jobs': -1, 'random_state': 0, 'reg_alpha': 0.16, 'reg_lambda': 0}),\n",
    "]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_scores = pd.DataFrame(columns=['Classifier', 'Test Score', 'Test Score 3*STD'])\n",
    "clf_preds = pd.DataFrame(train[targ_col])\n",
    "for i in range(len(classifiers)):\n",
    "    clf = classifiers[i]\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(train[feature_cols], train[targ_col])\n",
    "    \n",
    "    cv_results = cross_val_score(clf, train[feature_cols], train[targ_col], cv=skf)s_') else feature_cols], train[targ_col], cv=skf)\n",
    "    clf_scores.loc[i] = [clf_name, cv_results.mean(), cv_results.std() * 3]\n",
    "    clf_preds[clf_name] = clf.predict(train[feature_cols])\n",
    "clf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_heatmap(clf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores_info(model_name, scores):\n",
    "    mean = scores.mean() * 100\n",
    "    std_3 = scores.std() * 100 * 3\n",
    "    print(model_name, 'score mean: ', mean)\n",
    "    print(model_name, 'score 3 std range: ', mean - std_3, 'â€”', mean + std_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_classifiers = [\n",
    "    ('knn', KNeighborsClassifier(**{'n_jobs': -1, 'n_neighbors': 7})),\n",
    "    ('bag', BaggingClassifier(**{'max_samples': 0.1, 'n_estimators': 50, 'n_jobs': -1, 'random_state': 0})),\n",
    "    ('gbc', GradientBoostingClassifier(**{'learning_rate': 0.3, 'max_depth': 2, 'min_samples_split': 2, 'n_estimators': 10, 'random_state': 0})),\n",
    "    ('bnb', BernoulliNB(**{'alpha': 0.1})),\n",
    "    ('gnb', GaussianNB()),\n",
    "    ('xgb', XGBClassifier(**{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 10, 'n_jobs': -1, 'random_state': 0, 'reg_alpha': 0.16, 'reg_lambda': 2.56})),\n",
    "]\n",
    "\n",
    "vote_hard_clf = VotingClassifier(vote_classifiers, voting='hard')\n",
    "\n",
    "print_scores_info('Vote Hard', cross_val_score(vote_hard_clf, train[feature_cols], train[targ_col], cv=skf))\n",
    "\n",
    "vote_hard_clf.fit(train[feature_cols], train[targ_col])\n",
    "preds_test = vote_hard_clf.predict(data_test[feature_cols])\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': data_test.PassengerId, 'Survived': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
